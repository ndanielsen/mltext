{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework with Yelp reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This assignment uses a small subset of the data from Kaggle's [Yelp Business Rating Prediction](https://www.kaggle.com/c/yelp-recsys-2013) competition.\n",
    "\n",
    "**Description of the data:**\n",
    "\n",
    "- **`yelp.json`** is the original format of the file. **`yelp.csv`** contains the same data, in a more convenient format. Both of the files are in the course repo (in the **`data`** directory), so there is no need to download the data from the Kaggle website.\n",
    "- Each observation (row) in this dataset is a review of a particular business by a particular user.\n",
    "- The **stars** column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "- The **text** column is the text of the review.\n",
    "- The **cool** column is the number of \"cool\" votes this review received from other Yelp users. All reviews start with 0 \"cool\" votes, and there is no limit to how many \"cool\" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.\n",
    "- The **useful** and **funny** columns are similar to the **cool** column.\n",
    "\n",
    "**Goal:** Predict the star rating of a review using **only** the review text. (We will not be using the other columns.)\n",
    "\n",
    "**Tip:** After each task, I recommend that you check the shape and the contents of your objects, to confirm that they match your expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read **`yelp.csv`** into a Pandas DataFrame and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_file = '../data/yelp.csv'\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.777500</td>\n",
       "      <td>0.876800</td>\n",
       "      <td>1.409300</td>\n",
       "      <td>0.701300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.214636</td>\n",
       "      <td>2.067861</td>\n",
       "      <td>2.336647</td>\n",
       "      <td>1.907942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              stars          cool        useful         funny\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000\n",
       "mean       3.777500      0.876800      1.409300      0.701300\n",
       "std        1.214636      2.067861      2.336647      1.907942\n",
       "min        1.000000      0.000000      0.000000      0.000000\n",
       "25%        3.000000      0.000000      0.000000      0.000000\n",
       "50%        4.000000      0.000000      1.000000      0.000000\n",
       "75%        5.000000      1.000000      2.000000      1.000000\n",
       "max        5.000000     77.000000     76.000000     57.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nunique(df, columns=None):\n",
    "    if not columns:\n",
    "        raise Exception('Add Columns')\n",
    "    for col in columns:\n",
    "            num_unique = df[col].nunique()\n",
    "            print \"# unique %s : %s\" % (col, num_unique)    \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique business_id : 4174\n",
      "# unique user_id : 6403\n",
      "# unique type : 1\n",
      "# unique cool : 29\n",
      "# unique useful : 28\n",
      "# unique funny : 29\n"
     ]
    }
   ],
   "source": [
    "nunique(df, columns=['business_id', 'user_id', 'type', 'cool', 'useful', 'funny'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unique(df, columns=None):\n",
    "    if not columns:\n",
    "        raise Exception('Add Columns')\n",
    "    for col in columns:\n",
    "            num_unique = df[col].unique()\n",
    "            print \"'%s' has %s unique values \\n unique items: \\n %s \\n\\n\" % (col, len(num_unique), num_unique) \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'business_id' has 4174 unique values \n",
      " unique items: \n",
      " ['9yKzy9PApeiPPOUJEtnvkg' 'ZRJwVLyzEJq1VAihDhYiow' '6oRAC4uyJCsJl1X0WZpVSA'\n",
      " ..., 'qhIlkXgcC4j34lNTIqu9WA' 'JOZqBKIOB8WEBAWm7v1JFA'\n",
      " 'f96lWMIAUhYIYy9gOktivQ'] \n",
      "\n",
      "\n",
      "'user_id' has 6403 unique values \n",
      " unique items: \n",
      " ['rLtl8ZkDX5vH5nAx9C3q5Q' '0a2KyEL0d3Yb1V6aivbIuQ' '0hT2KtfLiobPvh6cDC8JQg'\n",
      " ..., 'gGbN1aKQHMgfQZkqlsuwzg' '0lyVoNazXa20WzUyZPLaQQ'\n",
      " 'KSBFytcdjPKZgXKQnYQdkA'] \n",
      "\n",
      "\n",
      "'type' has 1 unique values \n",
      " unique items: \n",
      " ['review'] \n",
      "\n",
      "\n",
      "'cool' has 29 unique values \n",
      " unique items: \n",
      " [ 2  0  1  4  7  3  5 11  6  8 16 28 12 13 10 22 17 18  9 14 21 15 19 20 23\n",
      " 77 27 38 32] \n",
      "\n",
      "\n",
      "'useful' has 28 unique values \n",
      " unique items: \n",
      " [ 5  0  1  2  3  7  4  6 16  9 17 19 28  8 15 10 12 23 20 11 13 18 14 24 76\n",
      " 31 38 30] \n",
      "\n",
      "\n",
      "'funny' has 29 unique values \n",
      " unique items: \n",
      " [ 0  1  4  2  3  8  9  6  5 39  7 12 16 20 27 11 13 17 10 30 22 14 19 18 23\n",
      " 21 15 24 57] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unique(df, columns=['business_id', 'user_id', 'type', 'cool', 'useful', 'funny'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapper(df, column):\n",
    "    num_unique = df[column].unique()\n",
    "    mapper = {user: num for num, user  in enumerate(num_unique) }\n",
    "    return mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unique_mapper(df, columns=None):\n",
    "    if not columns:\n",
    "        raise Exception('Add Columns')\n",
    "    for col in columns:\n",
    "        map_dict = mapper(df, col)\n",
    "        df[col] = df[col].map(map_dict)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_mapper(df, columns=['user_id', 'business_id', 'review_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>165</td>\n",
       "      <td>2012-07-28</td>\n",
       "      <td>9995</td>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>review</td>\n",
       "      <td>6398</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>783</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>9996</td>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>review</td>\n",
       "      <td>6399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1033</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>9997</td>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>review</td>\n",
       "      <td>6400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2562</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>9998</td>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>review</td>\n",
       "      <td>6401</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>341</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>9999</td>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>6402</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      business_id        date  review_id  stars  \\\n",
       "9995          165  2012-07-28       9995      3   \n",
       "9996          783  2012-01-18       9996      4   \n",
       "9997         1033  2010-11-16       9997      4   \n",
       "9998         2562  2012-12-02       9998      2   \n",
       "9999          341  2010-10-16       9999      5   \n",
       "\n",
       "                                                   text    type  user_id  \\\n",
       "9995  First visit...Had lunch here today - used my G...  review     6398   \n",
       "9996  Should be called house of deliciousness!\\n\\nI ...  review     6399   \n",
       "9997  I recently visited Olive and Ivy for business ...  review     6400   \n",
       "9998  My nephew just moved to Scottsdale recently so...  review     6401   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...  review     6402   \n",
       "\n",
       "      cool  useful  funny  \n",
       "9995     1       2      0  \n",
       "9996     0       0      0  \n",
       "9997     0       0      0  \n",
       "9998     0       0      0  \n",
       "9999     0       0      0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (Alternative)\n",
    "\n",
    "Ignore the **`yelp.csv`** file, and instead construct this DataFrame manually using **`yelp.json`**. This involves reading the file into Python, decoding the JSON, converting it to a DataFrame, and adding individual columns for each of the vote types.\n",
    "\n",
    "**Note:** This may be a challenging task, so I recommend skipping it unless you are fluent with Python and Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_file = '../data/yelp.json'\n",
    "\n",
    "reviews = []\n",
    "for line in open(json_file, 'r'):\n",
    "    review = json.loads(line)\n",
    "    review.update(review['votes'])\n",
    "    del review['votes']\n",
    "    reviews.append(review)\n",
    "\n",
    "json_dj = pd.DataFrame(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>0</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>5</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>0</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>0</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>0</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-yxfBYGB6SEqszmxJxd97A</td>\n",
       "      <td>4</td>\n",
       "      <td>2007-12-13</td>\n",
       "      <td>1</td>\n",
       "      <td>m2CKSsepBCoRYWxiRUsxAg</td>\n",
       "      <td>4</td>\n",
       "      <td>Quiessence is, simply put, beautiful.  Full wi...</td>\n",
       "      <td>review</td>\n",
       "      <td>3</td>\n",
       "      <td>sqYN3lNgvPbPCTRsMFu27g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zp713qNhx8d9KCJJnrw1xA</td>\n",
       "      <td>7</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>4</td>\n",
       "      <td>riFQ3vxNpP4rWLk_CSri2A</td>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>review</td>\n",
       "      <td>7</td>\n",
       "      <td>wFweIWhv2fREZV_dYkz_1g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hW0Ne_HTHEAgGF1rAdmR-g</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-12</td>\n",
       "      <td>0</td>\n",
       "      <td>JL7GXJ9u4YMx7Rzs05NfiQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Luckily, I didn't have to travel far to make m...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>1ieuYcKS7zeAv_U15AB13A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wNUea3IXZWD63bbOQaOH-g</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>0</td>\n",
       "      <td>XtnfnYmnJYi71yIuGsXIUA</td>\n",
       "      <td>4</td>\n",
       "      <td>Definitely come for Happy hour! Prices are ama...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>Vh_DlizgGhSqQh4qfZ2h6A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nMHhuYan8e3cONo3PornJA</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-08-11</td>\n",
       "      <td>0</td>\n",
       "      <td>jJAIXA46pU1swYyRCdfXtQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Nobuo shows his unique talents with everything...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>sUNkXg8-KFtCMQDV6zRzQg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AsSCv0q_BWqIe3mX2JqsOQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-16</td>\n",
       "      <td>1</td>\n",
       "      <td>E11jzpKz9Kw5K7fuARWfRw</td>\n",
       "      <td>5</td>\n",
       "      <td>The oldish man who owns the store is as sweet ...</td>\n",
       "      <td>review</td>\n",
       "      <td>3</td>\n",
       "      <td>-OMlS6yWkYjVldNhC31wYg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>e9nN4XxjdHj4qtKCOPq_vg</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-10-21</td>\n",
       "      <td>0</td>\n",
       "      <td>3rPt0LxF7rgmEUrznoH22w</td>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful Vietnamese sandwich shoppe. Their ba...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>C1rHp3dmepNea7XiouwB6Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>h53YuCiIDfEFSJCQpk8v1g</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>0</td>\n",
       "      <td>cGnKNX3I9rthE0-TH24-qA</td>\n",
       "      <td>5</td>\n",
       "      <td>They have a limited time thing going on right ...</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>UPtysDF6cUDUxq2KY-6Dcg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WGNIYMeXPyoWav1APUq7jA</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-12-23</td>\n",
       "      <td>0</td>\n",
       "      <td>FvEEw1_OsrYdvwLV5Hrliw</td>\n",
       "      <td>4</td>\n",
       "      <td>Good tattoo shop. Clean space, multiple artist...</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>Xm8HXE1JHqscXe5BKf0GFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yc5AH9H71xJidA_J2mChLA</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-20</td>\n",
       "      <td>0</td>\n",
       "      <td>pfUwBKYYmUXeiwrhDluQcw</td>\n",
       "      <td>4</td>\n",
       "      <td>I'm 2 weeks new to Phoenix. I looked up Irish ...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>JOG-4G4e8ae3lx_szHtR8g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vb9FPCEL6Ly24PNxLBaAFw</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-03-20</td>\n",
       "      <td>0</td>\n",
       "      <td>HvqmdqWcerVWO3Gs6zbrOw</td>\n",
       "      <td>2</td>\n",
       "      <td>Was it worth the 21$ for a salad and small piz...</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>ylWOj2y7TV2e3yYeWhu2QA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>supigcPNO9IKo6olaTNV-g</td>\n",
       "      <td>3</td>\n",
       "      <td>2008-10-12</td>\n",
       "      <td>2</td>\n",
       "      <td>HXP_0Ul-FCmA4f-k9CqvaQ</td>\n",
       "      <td>3</td>\n",
       "      <td>We went here on a Saturday afternoon and this ...</td>\n",
       "      <td>review</td>\n",
       "      <td>4</td>\n",
       "      <td>SBbftLzfYYKItOMFwOTIJg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>O510Re68mOy9dU490JTKCg</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-05-03</td>\n",
       "      <td>0</td>\n",
       "      <td>j4SIzrIy0WrmW4yr4--Khg</td>\n",
       "      <td>5</td>\n",
       "      <td>okay this is the best place EVER! i grew up sh...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>u1KWcbPMvXFEEYkZZ0Yktg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b5cEoKR8iQliq-yT2_O0LQ</td>\n",
       "      <td>5</td>\n",
       "      <td>2009-03-06</td>\n",
       "      <td>4</td>\n",
       "      <td>v0cTd3PNpYCkTyGKSpOfGA</td>\n",
       "      <td>3</td>\n",
       "      <td>I met a friend for lunch yesterday. \\n\\nLoved ...</td>\n",
       "      <td>review</td>\n",
       "      <td>6</td>\n",
       "      <td>UsULgP4bKA8RMzs8dQzcsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4JzzbSbK9wmlOBJZWYfuCg</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-11-17</td>\n",
       "      <td>1</td>\n",
       "      <td>a0lCu-j2Sk_kHQsZi_eNgw</td>\n",
       "      <td>4</td>\n",
       "      <td>They've gotten better and better for me in the...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>nDBly08j5URmrHQ2JCbyiw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8FNO4D3eozpIjj0k3q5Zbg</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-10-08</td>\n",
       "      <td>1</td>\n",
       "      <td>MuqugTuR5DdIPcZ2IVP3aQ</td>\n",
       "      <td>3</td>\n",
       "      <td>DVAP....\\n\\nYou have to go at least once in yo...</td>\n",
       "      <td>review</td>\n",
       "      <td>4</td>\n",
       "      <td>C6IOtaaYdLIT5fWd7ZYIuA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>tdcjXyFLMKAsvRhURNOkCg</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-06-28</td>\n",
       "      <td>2</td>\n",
       "      <td>LmuKVFh03Uz318VKnUWrxA</td>\n",
       "      <td>5</td>\n",
       "      <td>This place shouldn't even be reviewed - becaus...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>YN3ZLOdg8kpnfbVcIhuEZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>eFA9dqXT5EA_TrMgbo03QQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>0</td>\n",
       "      <td>CQYc8hgKxV4enApDkx0IhA</td>\n",
       "      <td>5</td>\n",
       "      <td>first time my friend and I went there... it wa...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>6lg55RIP23VhjYEBXJ8Njw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>IJ0o6b8bJFAbG6MjGfBebQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-09-05</td>\n",
       "      <td>1</td>\n",
       "      <td>Dx9sfFU6Zn0GYOckijom-g</td>\n",
       "      <td>1</td>\n",
       "      <td>U can go there n check the car out. If u wanna...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>zRlQEDYd_HKp0VS3hnAffA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JhupPnWfNlMJivnWB5druA</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-05-22</td>\n",
       "      <td>0</td>\n",
       "      <td>cFtQnKzn2VDpBedy_TxlvA</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this place! I have been coming here for...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>13xj6FSvYO0rZVRv5XZp4w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>wzP2yNpV5p04nh0injjymA</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-05-26</td>\n",
       "      <td>0</td>\n",
       "      <td>ChBeixVZerfFkeO0McdlbA</td>\n",
       "      <td>4</td>\n",
       "      <td>This place is great.  A nice little ole' fashi...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>qjmCVYkwP-HDa35jwYucbQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>kZ4TzrVX6qeF0OvrVTGVEw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love love LOVE this place. My boss (who is i...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>fpItLlgimq0nRltWOkuJJw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>wct7rZKyZqZftzmAU-vhWQ</td>\n",
       "      <td>2</td>\n",
       "      <td>2008-03-21</td>\n",
       "      <td>1</td>\n",
       "      <td>B5h25WK28rJjx4KHm4gr7g</td>\n",
       "      <td>4</td>\n",
       "      <td>Not that my review will mean much given the mo...</td>\n",
       "      <td>review</td>\n",
       "      <td>4</td>\n",
       "      <td>RRTraCQw77EU4yZh0BBTag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vz2zQQSjy-NnnKLZzjjoxA</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-03-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Y_ERKao0J5WsRiCtlKSNSA</td>\n",
       "      <td>4</td>\n",
       "      <td>Came here for breakfast yesterday, it had been...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>EP3cGJvYiuOwumerwADplg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>i213sY5rhkfCO8cD-FPr1A</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-07-12</td>\n",
       "      <td>0</td>\n",
       "      <td>hre97jjSwon4bn1muHKOJg</td>\n",
       "      <td>4</td>\n",
       "      <td>Always reliably good.  Great beer selection as...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>kpbhy1zPewGDmdNfNqQp-g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>R6aazv8FB-6BeanY3ag8kw</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-26</td>\n",
       "      <td>0</td>\n",
       "      <td>gP17ykqduf3AlewSaRb61w</td>\n",
       "      <td>5</td>\n",
       "      <td>This place is super cute lunch joint.  I had t...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>mtoKqaQjGPWEc5YZbrYV9w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>JOZqBKIOB8WEBAWm7v1JFA</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-07-22</td>\n",
       "      <td>1</td>\n",
       "      <td>QI9rfeWrZnvK5ojz8cEoRg</td>\n",
       "      <td>5</td>\n",
       "      <td>The staff is great, the food is great, even th...</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>uBAMd01ZtGXaHrRD6THNzg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>OllL0G9Kh_k1lx-2vrFDXQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-23</td>\n",
       "      <td>0</td>\n",
       "      <td>U23UfuxN9DpAU0Dslc5KjQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Yay, even though I miss living in Coronado I a...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>Gh1EXuS42DY3rV_MzFpJpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>XHr5mXFgobOHoxbPJxmYdg</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-28</td>\n",
       "      <td>0</td>\n",
       "      <td>udMiWjeG0OGcb4nNddDkBg</td>\n",
       "      <td>5</td>\n",
       "      <td>Wow!  Went on a Sunday around 11am - busy but ...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>yRYNx24kUDRRBfJu1Rcojg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>cdacUBBL2tDbDnB1EfhpQw</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-12-16</td>\n",
       "      <td>0</td>\n",
       "      <td>bVU-_x9ijxjEImNluy84OA</td>\n",
       "      <td>2</td>\n",
       "      <td>If Cowboy Ciao is the best restaurant in Scott...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>V9Uqt00HXwXT6mzsVCjMAw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>EWMwV5V9BxNs_U6nNVMeqw</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-10-20</td>\n",
       "      <td>0</td>\n",
       "      <td>g4LsVAoafmUDHiS-_yN4tA</td>\n",
       "      <td>5</td>\n",
       "      <td>When I lived in Phoenix, I was a regular at Fe...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>TLj3XaclA7V4ldJ5yNP-9Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>iDYzGVIF1TDWdjHNgNjCVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-09-11</td>\n",
       "      <td>0</td>\n",
       "      <td>bKjMcpNj0xSu2UI2EFQn1g</td>\n",
       "      <td>3</td>\n",
       "      <td>I was looking for chile rellenos and this plac...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2tUCLMHQKz4kA1VlRB_w0Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>iDYzGVIF1TDWdjHNgNjCVw</td>\n",
       "      <td>3</td>\n",
       "      <td>2012-10-30</td>\n",
       "      <td>3</td>\n",
       "      <td>qaNZyCUJA6Yp0mvPBCknPQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Why did I wait so long to try this neighborhoo...</td>\n",
       "      <td>review</td>\n",
       "      <td>6</td>\n",
       "      <td>Id-8-NMEKxeXBR44eUdDeA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>9Y3aQAVITkEJYe5vLZr13w</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>ZoTUU6EJ1OBNr7mhqxHBLw</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the place for a fabulos breakfast!! I ...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>vasHsAZEgLZGJDTlIweUYQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>GV1P1x9eRb4iZHCxj5_IjA</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-12-07</td>\n",
       "      <td>1</td>\n",
       "      <td>eVUs1C4yaVJNrc7SGTAheg</td>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommend. This is my second time here ...</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>bJFdmJJxfXgCYA5DMmyeqQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>GHYOl_cnERMOhkCK_mGAlA</td>\n",
       "      <td>6</td>\n",
       "      <td>2011-07-03</td>\n",
       "      <td>4</td>\n",
       "      <td>Q-y3jSqccdytKxAyo1J0Xg</td>\n",
       "      <td>5</td>\n",
       "      <td>5 stars for the great $5 happy hour specials. ...</td>\n",
       "      <td>review</td>\n",
       "      <td>6</td>\n",
       "      <td>xZvRLPJ1ixhFVomkXSfXAw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>AX8lx9wHNYT45lyd7pxaYw</td>\n",
       "      <td>10</td>\n",
       "      <td>2008-11-27</td>\n",
       "      <td>5</td>\n",
       "      <td>IyunTh7jnG7v3EYwfF3hPw</td>\n",
       "      <td>5</td>\n",
       "      <td>We brought the entire family to Giuseppe's las...</td>\n",
       "      <td>review</td>\n",
       "      <td>9</td>\n",
       "      <td>fczQCSmaWF78toLEmb0Zsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>KV-yJLmlODfUG1Mkds6kYw</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>rIgZgxJPWTacq3mV6DfWfg</td>\n",
       "      <td>4</td>\n",
       "      <td>Best corned beef sandwich I've had anywhere at...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>J-oVr0th2Y7ltPPOwy0Z8Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>24V8QQWO6VaVggHdxjQQ_A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-06</td>\n",
       "      <td>1</td>\n",
       "      <td>PqiIeFOiVr-tj_FtHGAH2g</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5 stars. \\n\\nWe decided to check this place ...</td>\n",
       "      <td>review</td>\n",
       "      <td>4</td>\n",
       "      <td>LaEj3VpQh7bgpAZLzSRRrw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>wepFVY82q_tuDzG6lQjHWw</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-02-12</td>\n",
       "      <td>2</td>\n",
       "      <td>spusZYROtBKw_5tv3gYm4Q</td>\n",
       "      <td>1</td>\n",
       "      <td>Went last night to Whore Foods to get basics t...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>W7zmm1uzlyUkEqpSG7PlBw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>EMGkbiCMfMTflQux-_JY7Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-17</td>\n",
       "      <td>0</td>\n",
       "      <td>wB-f0xfx7WIyrOsRJMkDOg</td>\n",
       "      <td>4</td>\n",
       "      <td>Awesome food! Little pricey but delicious. Lov...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>9MJAacmjxtctbI3xncsK5Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>oCA2OZcd_Jo_ggVmUx3WVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>ijPZPKKWDqdWOIqYkUsJJw</td>\n",
       "      <td>4</td>\n",
       "      <td>I came here in December and look forward to my...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>yzwPJdn6yd2ccZqfy4LhUA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>r-a-Cn9hxdEnYTtVTB5bMQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-04-07</td>\n",
       "      <td>0</td>\n",
       "      <td>j9HwZZoBBmJgOlqDSuJcxg</td>\n",
       "      <td>1</td>\n",
       "      <td>The food is delicious.  The service:  discrimi...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>toPtsUtYoRB-5-ThrOy2Fg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>xY1sPHTA2RGVFlh5tZhs9g</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-06-02</td>\n",
       "      <td>0</td>\n",
       "      <td>TM8hdYqs5Zi1jO5Yrq6E0g</td>\n",
       "      <td>4</td>\n",
       "      <td>For our first time we had a great time! Our se...</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>GvaNZY4poCcd3H4WxHjrLQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>mQUC-ATrFuMQSaDQb93Pug</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>0</td>\n",
       "      <td>ta2P9joJqeFB8BzFp-AzjA</td>\n",
       "      <td>5</td>\n",
       "      <td>Great food and service! Country food at its best!</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>fKaO8fR1IAcfvZb6cBrs2w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>R8VwdLyvsp9iybNqRvm94g</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-10-03</td>\n",
       "      <td>1</td>\n",
       "      <td>pcEeHdAJPoFNF23es0kKWg</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes I do rock the hipster joints.  I dig this ...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>b92Y3tyWTQQZ5FLifex62Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>WJ5mq4EiWYAA4Vif0xDfdg</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-12-05</td>\n",
       "      <td>0</td>\n",
       "      <td>EuHX-39FR7tyyG1ElvN1Jw</td>\n",
       "      <td>5</td>\n",
       "      <td>Only 4 stars? \\n\\n(A few notes: The folks that...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>hTau-iNZFwoNsPCaiIUTEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>f96lWMIAUhYIYy9gOktivQ</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-03-10</td>\n",
       "      <td>2</td>\n",
       "      <td>YF17z7HWlMj6aezZc-pVEw</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm not normally one to jump at reviewing a ch...</td>\n",
       "      <td>review</td>\n",
       "      <td>3</td>\n",
       "      <td>W_QXYA7A0IhMrvbckz7eVg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>maB4VHseFUY2TmPtAQnB9Q</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-06-27</td>\n",
       "      <td>0</td>\n",
       "      <td>SNnyYHI9rw9TTltVX3TF-A</td>\n",
       "      <td>4</td>\n",
       "      <td>Judging by some of the reviews, maybe I went o...</td>\n",
       "      <td>review</td>\n",
       "      <td>1</td>\n",
       "      <td>T46gxPbJMWmlLyr7GxQLyQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>L3BSpFvxcNf3T_teitgt6A</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-03-19</td>\n",
       "      <td>1</td>\n",
       "      <td>0nxb1gIGFgk3WbC5zwhKZg</td>\n",
       "      <td>5</td>\n",
       "      <td>Let's see...what is there NOT to like about Su...</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>OzOZv-Knlw3oz9K5Kh5S6A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>VY_tvNUCCXGXQeSvJl757Q</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-07-28</td>\n",
       "      <td>0</td>\n",
       "      <td>Ubyfp2RSDYW0g7Mbr8N3iA</td>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "      <td>_eqQoPtQ3e3UxLE4faT6ow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>EKzMHI1tip8rC1-ZAy64yg</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>0</td>\n",
       "      <td>2XyIOQKbVFb6uXQdJ0RzlQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>ROru4uk5SaYc3rg8IU7SQw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>53YGfwmbW73JhFiemNeyzQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>0</td>\n",
       "      <td>jyznYkIbpqVmlsZxSDSypA</td>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>gGbN1aKQHMgfQZkqlsuwzg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9SKdOoDHcFoxK5ZtsgHJoA</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>0</td>\n",
       "      <td>5UKq9WQE1qQbJ0DJbc-B6Q</td>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>0lyVoNazXa20WzUyZPLaQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>pF7uRzygyZsltbmVpjIyvw</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>0</td>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>KSBFytcdjPKZgXKQnYQdkA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id  cool        date  funny               review_id  \\\n",
       "0     9yKzy9PApeiPPOUJEtnvkg     2  2011-01-26      0  fWKvX83p0-ka4JS3dc6E5A   \n",
       "1     ZRJwVLyzEJq1VAihDhYiow     0  2011-07-27      0  IjZ33sJrzXqU-0X6U8NwyA   \n",
       "2     6oRAC4uyJCsJl1X0WZpVSA     0  2012-06-14      0  IESLBzqUCLdSzSqm0eCSxQ   \n",
       "3     _1QQZuf4zZOyFCvXc0o6Vg     1  2010-05-27      0  G-WvGaISbqqaMHlNnByodA   \n",
       "4     6ozycU1RpktNG2-1BroVtw     0  2012-01-05      0  1uJFq2r5QfJG_6ExMRCaGw   \n",
       "5     -yxfBYGB6SEqszmxJxd97A     4  2007-12-13      1  m2CKSsepBCoRYWxiRUsxAg   \n",
       "6     zp713qNhx8d9KCJJnrw1xA     7  2010-02-12      4  riFQ3vxNpP4rWLk_CSri2A   \n",
       "7     hW0Ne_HTHEAgGF1rAdmR-g     0  2012-07-12      0  JL7GXJ9u4YMx7Rzs05NfiQ   \n",
       "8     wNUea3IXZWD63bbOQaOH-g     0  2012-08-17      0  XtnfnYmnJYi71yIuGsXIUA   \n",
       "9     nMHhuYan8e3cONo3PornJA     0  2010-08-11      0  jJAIXA46pU1swYyRCdfXtQ   \n",
       "10    AsSCv0q_BWqIe3mX2JqsOQ     1  2010-06-16      1  E11jzpKz9Kw5K7fuARWfRw   \n",
       "11    e9nN4XxjdHj4qtKCOPq_vg     1  2011-10-21      0  3rPt0LxF7rgmEUrznoH22w   \n",
       "12    h53YuCiIDfEFSJCQpk8v1g     1  2010-01-11      0  cGnKNX3I9rthE0-TH24-qA   \n",
       "13    WGNIYMeXPyoWav1APUq7jA     1  2011-12-23      0  FvEEw1_OsrYdvwLV5Hrliw   \n",
       "14    yc5AH9H71xJidA_J2mChLA     1  2010-05-20      0  pfUwBKYYmUXeiwrhDluQcw   \n",
       "15    Vb9FPCEL6Ly24PNxLBaAFw     0  2011-03-20      0  HvqmdqWcerVWO3Gs6zbrOw   \n",
       "16    supigcPNO9IKo6olaTNV-g     3  2008-10-12      2  HXP_0Ul-FCmA4f-k9CqvaQ   \n",
       "17    O510Re68mOy9dU490JTKCg     0  2010-05-03      0  j4SIzrIy0WrmW4yr4--Khg   \n",
       "18    b5cEoKR8iQliq-yT2_O0LQ     5  2009-03-06      4  v0cTd3PNpYCkTyGKSpOfGA   \n",
       "19    4JzzbSbK9wmlOBJZWYfuCg     1  2011-11-17      1  a0lCu-j2Sk_kHQsZi_eNgw   \n",
       "20    8FNO4D3eozpIjj0k3q5Zbg     2  2008-10-08      1  MuqugTuR5DdIPcZ2IVP3aQ   \n",
       "21    tdcjXyFLMKAsvRhURNOkCg     1  2011-06-28      2  LmuKVFh03Uz318VKnUWrxA   \n",
       "22    eFA9dqXT5EA_TrMgbo03QQ     0  2011-07-13      0  CQYc8hgKxV4enApDkx0IhA   \n",
       "23    IJ0o6b8bJFAbG6MjGfBebQ     0  2010-09-05      1  Dx9sfFU6Zn0GYOckijom-g   \n",
       "24    JhupPnWfNlMJivnWB5druA     0  2011-05-22      0  cFtQnKzn2VDpBedy_TxlvA   \n",
       "25    wzP2yNpV5p04nh0injjymA     0  2010-05-26      0  ChBeixVZerfFkeO0McdlbA   \n",
       "26    qjmCVYkwP-HDa35jwYucbQ     0  2013-01-03      0  kZ4TzrVX6qeF0OvrVTGVEw   \n",
       "27    wct7rZKyZqZftzmAU-vhWQ     2  2008-03-21      1  B5h25WK28rJjx4KHm4gr7g   \n",
       "28    vz2zQQSjy-NnnKLZzjjoxA     1  2011-03-30      1  Y_ERKao0J5WsRiCtlKSNSA   \n",
       "29    i213sY5rhkfCO8cD-FPr1A     0  2012-07-12      0  hre97jjSwon4bn1muHKOJg   \n",
       "...                      ...   ...         ...    ...                     ...   \n",
       "9970  R6aazv8FB-6BeanY3ag8kw     0  2009-09-26      0  gP17ykqduf3AlewSaRb61w   \n",
       "9971  JOZqBKIOB8WEBAWm7v1JFA     1  2008-07-22      1  QI9rfeWrZnvK5ojz8cEoRg   \n",
       "9972  OllL0G9Kh_k1lx-2vrFDXQ     0  2012-10-23      0  U23UfuxN9DpAU0Dslc5KjQ   \n",
       "9973  XHr5mXFgobOHoxbPJxmYdg     0  2009-09-28      0  udMiWjeG0OGcb4nNddDkBg   \n",
       "9974  cdacUBBL2tDbDnB1EfhpQw     0  2009-12-16      0  bVU-_x9ijxjEImNluy84OA   \n",
       "9975  EWMwV5V9BxNs_U6nNVMeqw     1  2007-10-20      0  g4LsVAoafmUDHiS-_yN4tA   \n",
       "9976  iDYzGVIF1TDWdjHNgNjCVw     0  2009-09-11      0  bKjMcpNj0xSu2UI2EFQn1g   \n",
       "9977  iDYzGVIF1TDWdjHNgNjCVw     3  2012-10-30      3  qaNZyCUJA6Yp0mvPBCknPQ   \n",
       "9978  9Y3aQAVITkEJYe5vLZr13w     0  2010-04-01      0  ZoTUU6EJ1OBNr7mhqxHBLw   \n",
       "9979  GV1P1x9eRb4iZHCxj5_IjA     2  2012-12-07      1  eVUs1C4yaVJNrc7SGTAheg   \n",
       "9980  GHYOl_cnERMOhkCK_mGAlA     6  2011-07-03      4  Q-y3jSqccdytKxAyo1J0Xg   \n",
       "9981  AX8lx9wHNYT45lyd7pxaYw    10  2008-11-27      5  IyunTh7jnG7v3EYwfF3hPw   \n",
       "9982  KV-yJLmlODfUG1Mkds6kYw     0  2012-02-25      0  rIgZgxJPWTacq3mV6DfWfg   \n",
       "9983  24V8QQWO6VaVggHdxjQQ_A     1  2010-06-06      1  PqiIeFOiVr-tj_FtHGAH2g   \n",
       "9984  wepFVY82q_tuDzG6lQjHWw     0  2012-02-12      2  spusZYROtBKw_5tv3gYm4Q   \n",
       "9985  EMGkbiCMfMTflQux-_JY7Q     0  2012-10-17      0  wB-f0xfx7WIyrOsRJMkDOg   \n",
       "9986  oCA2OZcd_Jo_ggVmUx3WVw     0  2012-03-31      0  ijPZPKKWDqdWOIqYkUsJJw   \n",
       "9987  r-a-Cn9hxdEnYTtVTB5bMQ     0  2012-04-07      0  j9HwZZoBBmJgOlqDSuJcxg   \n",
       "9988  xY1sPHTA2RGVFlh5tZhs9g     0  2012-06-02      0  TM8hdYqs5Zi1jO5Yrq6E0g   \n",
       "9989  mQUC-ATrFuMQSaDQb93Pug     0  2011-10-01      0  ta2P9joJqeFB8BzFp-AzjA   \n",
       "9990  R8VwdLyvsp9iybNqRvm94g     1  2011-10-03      1  pcEeHdAJPoFNF23es0kKWg   \n",
       "9991  WJ5mq4EiWYAA4Vif0xDfdg     1  2011-12-05      0  EuHX-39FR7tyyG1ElvN1Jw   \n",
       "9992  f96lWMIAUhYIYy9gOktivQ     2  2009-03-10      2  YF17z7HWlMj6aezZc-pVEw   \n",
       "9993  maB4VHseFUY2TmPtAQnB9Q     1  2011-06-27      0  SNnyYHI9rw9TTltVX3TF-A   \n",
       "9994  L3BSpFvxcNf3T_teitgt6A     1  2012-03-19      1  0nxb1gIGFgk3WbC5zwhKZg   \n",
       "9995  VY_tvNUCCXGXQeSvJl757Q     1  2012-07-28      0  Ubyfp2RSDYW0g7Mbr8N3iA   \n",
       "9996  EKzMHI1tip8rC1-ZAy64yg     0  2012-01-18      0  2XyIOQKbVFb6uXQdJ0RzlQ   \n",
       "9997  53YGfwmbW73JhFiemNeyzQ     0  2010-11-16      0  jyznYkIbpqVmlsZxSDSypA   \n",
       "9998  9SKdOoDHcFoxK5ZtsgHJoA     0  2012-12-02      0  5UKq9WQE1qQbJ0DJbc-B6Q   \n",
       "9999  pF7uRzygyZsltbmVpjIyvw     0  2010-10-16      0  vWSmOhg2ID1MNZHaWapGbA   \n",
       "\n",
       "      stars                                               text    type  \\\n",
       "0         5  My wife took me here on my birthday for breakf...  review   \n",
       "1         5  I have no idea why some people give bad review...  review   \n",
       "2         4  love the gyro plate. Rice is so good and I als...  review   \n",
       "3         5  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4         5  General Manager Scott Petello is a good egg!!!...  review   \n",
       "5         4  Quiessence is, simply put, beautiful.  Full wi...  review   \n",
       "6         5  Drop what you're doing and drive here. After I...  review   \n",
       "7         4  Luckily, I didn't have to travel far to make m...  review   \n",
       "8         4  Definitely come for Happy hour! Prices are ama...  review   \n",
       "9         5  Nobuo shows his unique talents with everything...  review   \n",
       "10        5  The oldish man who owns the store is as sweet ...  review   \n",
       "11        5  Wonderful Vietnamese sandwich shoppe. Their ba...  review   \n",
       "12        5  They have a limited time thing going on right ...  review   \n",
       "13        4  Good tattoo shop. Clean space, multiple artist...  review   \n",
       "14        4  I'm 2 weeks new to Phoenix. I looked up Irish ...  review   \n",
       "15        2  Was it worth the 21$ for a salad and small piz...  review   \n",
       "16        3  We went here on a Saturday afternoon and this ...  review   \n",
       "17        5  okay this is the best place EVER! i grew up sh...  review   \n",
       "18        3  I met a friend for lunch yesterday. \\n\\nLoved ...  review   \n",
       "19        4  They've gotten better and better for me in the...  review   \n",
       "20        3  DVAP....\\n\\nYou have to go at least once in yo...  review   \n",
       "21        5  This place shouldn't even be reviewed - becaus...  review   \n",
       "22        5  first time my friend and I went there... it wa...  review   \n",
       "23        1  U can go there n check the car out. If u wanna...  review   \n",
       "24        5  I love this place! I have been coming here for...  review   \n",
       "25        4  This place is great.  A nice little ole' fashi...  review   \n",
       "26        5  I love love LOVE this place. My boss (who is i...  review   \n",
       "27        4  Not that my review will mean much given the mo...  review   \n",
       "28        4  Came here for breakfast yesterday, it had been...  review   \n",
       "29        4  Always reliably good.  Great beer selection as...  review   \n",
       "...     ...                                                ...     ...   \n",
       "9970      5  This place is super cute lunch joint.  I had t...  review   \n",
       "9971      5  The staff is great, the food is great, even th...  review   \n",
       "9972      4  Yay, even though I miss living in Coronado I a...  review   \n",
       "9973      5  Wow!  Went on a Sunday around 11am - busy but ...  review   \n",
       "9974      2  If Cowboy Ciao is the best restaurant in Scott...  review   \n",
       "9975      5  When I lived in Phoenix, I was a regular at Fe...  review   \n",
       "9976      3  I was looking for chile rellenos and this plac...  review   \n",
       "9977      5  Why did I wait so long to try this neighborhoo...  review   \n",
       "9978      5  This is the place for a fabulos breakfast!! I ...  review   \n",
       "9979      5  Highly recommend. This is my second time here ...  review   \n",
       "9980      5  5 stars for the great $5 happy hour specials. ...  review   \n",
       "9981      5  We brought the entire family to Giuseppe's las...  review   \n",
       "9982      4  Best corned beef sandwich I've had anywhere at...  review   \n",
       "9983      3  3.5 stars. \\n\\nWe decided to check this place ...  review   \n",
       "9984      1  Went last night to Whore Foods to get basics t...  review   \n",
       "9985      4  Awesome food! Little pricey but delicious. Lov...  review   \n",
       "9986      4  I came here in December and look forward to my...  review   \n",
       "9987      1  The food is delicious.  The service:  discrimi...  review   \n",
       "9988      4  For our first time we had a great time! Our se...  review   \n",
       "9989      5  Great food and service! Country food at its best!  review   \n",
       "9990      5  Yes I do rock the hipster joints.  I dig this ...  review   \n",
       "9991      5  Only 4 stars? \\n\\n(A few notes: The folks that...  review   \n",
       "9992      5  I'm not normally one to jump at reviewing a ch...  review   \n",
       "9993      4  Judging by some of the reviews, maybe I went o...  review   \n",
       "9994      5  Let's see...what is there NOT to like about Su...  review   \n",
       "9995      3  First visit...Had lunch here today - used my G...  review   \n",
       "9996      4  Should be called house of deliciousness!\\n\\nI ...  review   \n",
       "9997      4  I recently visited Olive and Ivy for business ...  review   \n",
       "9998      2  My nephew just moved to Scottsdale recently so...  review   \n",
       "9999      5  4-5 locations.. all 4.5 star average.. I think...  review   \n",
       "\n",
       "      useful                 user_id  \n",
       "0          5  rLtl8ZkDX5vH5nAx9C3q5Q  \n",
       "1          0  0a2KyEL0d3Yb1V6aivbIuQ  \n",
       "2          1  0hT2KtfLiobPvh6cDC8JQg  \n",
       "3          2  uZetl9T0NcROGOyFfughhg  \n",
       "4          0  vYmM4KTsC8ZfQBg-j5MWkw  \n",
       "5          3  sqYN3lNgvPbPCTRsMFu27g  \n",
       "6          7  wFweIWhv2fREZV_dYkz_1g  \n",
       "7          1  1ieuYcKS7zeAv_U15AB13A  \n",
       "8          0  Vh_DlizgGhSqQh4qfZ2h6A  \n",
       "9          1  sUNkXg8-KFtCMQDV6zRzQg  \n",
       "10         3  -OMlS6yWkYjVldNhC31wYg  \n",
       "11         1  C1rHp3dmepNea7XiouwB6Q  \n",
       "12         2  UPtysDF6cUDUxq2KY-6Dcg  \n",
       "13         2  Xm8HXE1JHqscXe5BKf0GFQ  \n",
       "14         1  JOG-4G4e8ae3lx_szHtR8g  \n",
       "15         2  ylWOj2y7TV2e3yYeWhu2QA  \n",
       "16         4  SBbftLzfYYKItOMFwOTIJg  \n",
       "17         0  u1KWcbPMvXFEEYkZZ0Yktg  \n",
       "18         6  UsULgP4bKA8RMzs8dQzcsA  \n",
       "19         1  nDBly08j5URmrHQ2JCbyiw  \n",
       "20         4  C6IOtaaYdLIT5fWd7ZYIuA  \n",
       "21         1  YN3ZLOdg8kpnfbVcIhuEZA  \n",
       "22         0  6lg55RIP23VhjYEBXJ8Njw  \n",
       "23         1  zRlQEDYd_HKp0VS3hnAffA  \n",
       "24         1  13xj6FSvYO0rZVRv5XZp4w  \n",
       "25         0  rLtl8ZkDX5vH5nAx9C3q5Q  \n",
       "26         0  fpItLlgimq0nRltWOkuJJw  \n",
       "27         4  RRTraCQw77EU4yZh0BBTag  \n",
       "28         1  EP3cGJvYiuOwumerwADplg  \n",
       "29         1  kpbhy1zPewGDmdNfNqQp-g  \n",
       "...      ...                     ...  \n",
       "9970       0  mtoKqaQjGPWEc5YZbrYV9w  \n",
       "9971       2  uBAMd01ZtGXaHrRD6THNzg  \n",
       "9972       0  Gh1EXuS42DY3rV_MzFpJpg  \n",
       "9973       0  yRYNx24kUDRRBfJu1Rcojg  \n",
       "9974       0  V9Uqt00HXwXT6mzsVCjMAw  \n",
       "9975       1  TLj3XaclA7V4ldJ5yNP-9Q  \n",
       "9976       0  2tUCLMHQKz4kA1VlRB_w0Q  \n",
       "9977       6  Id-8-NMEKxeXBR44eUdDeA  \n",
       "9978       1  vasHsAZEgLZGJDTlIweUYQ  \n",
       "9979       2  bJFdmJJxfXgCYA5DMmyeqQ  \n",
       "9980       6  xZvRLPJ1ixhFVomkXSfXAw  \n",
       "9981       9  fczQCSmaWF78toLEmb0Zsw  \n",
       "9982       0  J-oVr0th2Y7ltPPOwy0Z8Q  \n",
       "9983       4  LaEj3VpQh7bgpAZLzSRRrw  \n",
       "9984       1  W7zmm1uzlyUkEqpSG7PlBw  \n",
       "9985       0  9MJAacmjxtctbI3xncsK5Q  \n",
       "9986       0  yzwPJdn6yd2ccZqfy4LhUA  \n",
       "9987       0  toPtsUtYoRB-5-ThrOy2Fg  \n",
       "9988       2  GvaNZY4poCcd3H4WxHjrLQ  \n",
       "9989       1  fKaO8fR1IAcfvZb6cBrs2w  \n",
       "9990       1  b92Y3tyWTQQZ5FLifex62Q  \n",
       "9991       1  hTau-iNZFwoNsPCaiIUTEA  \n",
       "9992       3  W_QXYA7A0IhMrvbckz7eVg  \n",
       "9993       1  T46gxPbJMWmlLyr7GxQLyQ  \n",
       "9994       2  OzOZv-Knlw3oz9K5Kh5S6A  \n",
       "9995       2  _eqQoPtQ3e3UxLE4faT6ow  \n",
       "9996       0  ROru4uk5SaYc3rg8IU7SQw  \n",
       "9997       0  gGbN1aKQHMgfQZkqlsuwzg  \n",
       "9998       0  0lyVoNazXa20WzUyZPLaQQ  \n",
       "9999       0  KSBFytcdjPKZgXKQnYQdkA  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(json_dj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns) == len(json_dj.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# unique business_id : 4174\n",
      "# unique user_id : 6403\n",
      "# unique type : 1\n",
      "# unique cool : 29\n",
      "# unique useful : 28\n",
      "# unique funny : 29\n"
     ]
    }
   ],
   "source": [
    "nunique(json_dj, columns=['business_id', 'user_id', 'type', 'cool', 'useful', 'funny'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Create a new DataFrame that only contains the **5-star** and **1-star** reviews.\n",
    "\n",
    "- **Hint:** You will need to filter the DataFrame using an OR condition. [Working with DataFrames](http://www.gregreda.com/2013/10/26/working-with-pandas-dataframes/) has an example of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = df[(df.stars==1) | (df.stars==5)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ndanielsen/.virtualenvs/mltext/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "dfs['stars'] = dfs.stars.map({5:1, 1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   business_id        date  review_id  stars  \\\n",
       "0            0  2011-01-26          0      1   \n",
       "\n",
       "                                                text    type  user_id  cool  \\\n",
       "0  My wife took me here on my birthday for breakf...  review        0     2   \n",
       "\n",
       "   useful  funny  \n",
       "0       5      0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the **review text** as the only feature and the **star rating** as the response.\n",
    "\n",
    "- **Hint:** Keep in mind that X should be a Pandas Series (not a DataFrame), since we will pass it to CountVectorizer in the task that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = ['text']\n",
    "X = dfs.text\n",
    "y = dfs.stars \n",
    "\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "Use CountVectorizer to create **document-term matrices** from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vect = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "# vect = CountVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3064x150034 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 307258 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn training data vocabulary, then create document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1022x150034 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 59818 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_tokens = vect.get_feature_names()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Use Multinomial Naive Bayes to **predict the star rating** for the reviews in the testing set, and then **calculate the accuracy** and **print the confusion matrix**.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains how to interpret both classification accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics.classification.classification_report>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "metrics.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nb_models(X_train_dtm, X_test_dtm, y_train, y_test, clf=None):\n",
    "    nb = clf()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    \n",
    "    y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "    accuracy_score = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "    \n",
    "    \n",
    "    return \"\"\"Model: %s \\n \n",
    "    Accuracy Score: %s \\n \n",
    "    ROC AUC Score: %s \\n \n",
    "    Confusion Matrix: %s\n",
    "    \n",
    "    \"\"\" % (clf, accuracy_score, roc_auc, confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'> \n",
      " \n",
      "    Accuracy Score: 0.853228962818 \n",
      " \n",
      "    ROC AUC Score: 0.770704705821 \n",
      " \n",
      "    Confusion Matrix: [[ 35 149]\n",
      " [  1 837]]\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print nb_models(X_train_dtm, X_test_dtm, y_train, y_test, clf=MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.naive_bayes.BernoulliNB'> \n",
      " \n",
      "    Accuracy Score: 0.820939334638 \n",
      " \n",
      "    ROC AUC Score: 0.502717391304 \n",
      " \n",
      "    Confusion Matrix: [[  1 183]\n",
      " [  0 838]]\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print nb_models(X_train_dtm, X_test_dtm, y_train, y_test, clf=BernoulliNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.linear_model.logistic.LogisticRegression'> \n",
      " \n",
      "    Accuracy Score: 0.930528375734 \n",
      " \n",
      "    ROC AUC Score: 0.967981477638 \n",
      " \n",
      "    Confusion Matrix: [[135  49]\n",
      " [ 22 816]]\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print nb_models(X_train_dtm, X_test_dtm, y_train, y_test, clf=LogisticRegression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 (Challenge)\n",
    "\n",
    "Calculate the **null accuracy**, which is the classification accuracy that could be achieved by always predicting the most frequent class.\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains null accuracy and demonstrates two ways to calculate it, though only one of those ways will work in this case. Alternatively, you can come up with your own method to calculate null accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy: 0.819960861057\n"
     ]
    }
   ],
   "source": [
    "print('Null accuracy: %s') % max(y_test.mean(), 1 - y_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81669114047968672"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def null_accuracy(y):\n",
    "    high = y.mean()\n",
    "    low = 1 - y.mean()\n",
    "    \n",
    "    return max(high, low)\n",
    "null_accuracy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 (Challenge)\n",
    "\n",
    "Calculate which 5 tokens are the most predictive of **5-star reviews**, and which 5 tokens are the most predictive of **1-star reviews**.\n",
    "\n",
    "- **Hint:** Use the `feature_count_` attribute from the Naive Bayes model object as a shortcut, so that you don't have to do any NumPy math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB\n",
    "nb = clf()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "accuracy_score = metrics.accuracy_score(y_test, y_pred_class)\n",
    "roc_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 26.   1.   1. ...,   0.   0.   0.]\n",
      " [ 39.   0.   0. ...,   1.   1.   1.]]\n"
     ]
    }
   ],
   "source": [
    "features_count = nb.feature_count_ \n",
    "\n",
    "print features_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -9.02763207 -11.63032176 -11.63032176 ..., -12.32346894 -12.32346894\n",
      "  -12.32346894]\n",
      " [ -9.23596182 -12.92484128 -12.92484128 ..., -12.23169409 -12.23169409\n",
      "  -12.23169409]]\n"
     ]
    }
   ],
   "source": [
    "features_log = nb.feature_log_prob_\n",
    "print features_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00', u'00 00', u'00 15', u'00 24', u'00 25']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_df = pd.DataFrame(features_count, columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 00</th>\n",
       "      <th>00 15</th>\n",
       "      <th>00 24</th>\n",
       "      <th>00 25</th>\n",
       "      <th>00 30</th>\n",
       "      <th>00 50</th>\n",
       "      <th>00 actually</th>\n",
       "      <th>00 amazing</th>\n",
       "      <th>00 arriving</th>\n",
       "      <th>...</th>\n",
       "      <th>zwiebel</th>\n",
       "      <th>zwiebel kräuter</th>\n",
       "      <th>zzed</th>\n",
       "      <th>zzed pants</th>\n",
       "      <th>éclairs</th>\n",
       "      <th>éclairs napoleons</th>\n",
       "      <th>école</th>\n",
       "      <th>école lenôtre</th>\n",
       "      <th>ém</th>\n",
       "      <th>ém huge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.027632</td>\n",
       "      <td>-11.630322</td>\n",
       "      <td>-11.630322</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-11.630322</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-11.630322</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "      <td>-12.323469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.235962</td>\n",
       "      <td>-12.924841</td>\n",
       "      <td>-12.924841</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.924841</td>\n",
       "      <td>-11.826229</td>\n",
       "      <td>-12.924841</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "      <td>-12.231694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 150034 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00      00 00      00 15      00 24      00 25      00 30      00 50  \\\n",
       "0 -9.027632 -11.630322 -11.630322 -12.323469 -12.323469 -11.630322 -12.323469   \n",
       "1 -9.235962 -12.924841 -12.924841 -12.231694 -12.231694 -12.924841 -11.826229   \n",
       "\n",
       "   00 actually  00 amazing  00 arriving    ...        zwiebel  \\\n",
       "0   -11.630322  -12.323469   -12.323469    ...     -12.323469   \n",
       "1   -12.924841  -12.231694   -12.231694    ...     -12.231694   \n",
       "\n",
       "   zwiebel kräuter       zzed  zzed pants    éclairs  éclairs napoleons  \\\n",
       "0       -12.323469 -12.323469  -12.323469 -12.323469         -12.323469   \n",
       "1       -12.231694 -12.231694  -12.231694 -12.231694         -12.231694   \n",
       "\n",
       "       école  école lenôtre         ém    ém huge  \n",
       "0 -12.323469     -12.323469 -12.323469 -12.323469  \n",
       "1 -12.231694     -12.231694 -12.231694 -12.231694  \n",
       "\n",
       "[2 rows x 150034 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_df = pd.DataFrame(features_log, columns=vect.get_feature_names())\n",
    "fl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fl_df_stacked = fl_df.head(2).stack().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>-8.074974</td>\n",
       "      <td>-5.610288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>-6.367632</td>\n",
       "      <td>-5.620998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>-6.280836</td>\n",
       "      <td>-5.800363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>-6.868148</td>\n",
       "      <td>-5.805206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-6.586897</td>\n",
       "      <td>-6.066276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "great -8.074974 -5.610288\n",
       "place -6.367632 -5.620998\n",
       "food  -6.280836 -5.800363\n",
       "good  -6.868148 -5.805206\n",
       "just  -6.586897 -6.066276"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_df_stacked.sort_values(1, ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>says figured</th>\n",
       "      <td>-11.630322</td>\n",
       "      <td>-12.924841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sank waders</th>\n",
       "      <td>-11.630322</td>\n",
       "      <td>-12.924841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sank</th>\n",
       "      <td>-11.630322</td>\n",
       "      <td>-12.924841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitizing tools</th>\n",
       "      <td>-11.630322</td>\n",
       "      <td>-12.924841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitizing</th>\n",
       "      <td>-11.630322</td>\n",
       "      <td>-12.924841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0          1\n",
       "says figured     -11.630322 -12.924841\n",
       "sank waders      -11.630322 -12.924841\n",
       "sank             -11.630322 -12.924841\n",
       "sanitizing tools -11.630322 -12.924841\n",
       "sanitizing       -11.630322 -12.924841"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fl_df_stacked.sort_values(1, ascending=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 00</th>\n",
       "      <th>00 15</th>\n",
       "      <th>00 24</th>\n",
       "      <th>00 25</th>\n",
       "      <th>00 30</th>\n",
       "      <th>00 50</th>\n",
       "      <th>00 actually</th>\n",
       "      <th>00 amazing</th>\n",
       "      <th>00 arriving</th>\n",
       "      <th>...</th>\n",
       "      <th>zwiebel</th>\n",
       "      <th>zwiebel kräuter</th>\n",
       "      <th>zzed</th>\n",
       "      <th>zzed pants</th>\n",
       "      <th>éclairs</th>\n",
       "      <th>éclairs napoleons</th>\n",
       "      <th>école</th>\n",
       "      <th>école lenôtre</th>\n",
       "      <th>ém</th>\n",
       "      <th>ém huge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 150034 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  00 00  00 15  00 24  00 25  00 30  00 50  00 actually  00 amazing  \\\n",
       "0  26      1      1      0      0      1      0            1           0   \n",
       "1  39      0      0      1      1      0      2            0           1   \n",
       "\n",
       "   00 arriving   ...     zwiebel  zwiebel kräuter  zzed  zzed pants  éclairs  \\\n",
       "0            0   ...           0                0     0           0        0   \n",
       "1            1   ...           1                1     1           1        1   \n",
       "\n",
       "   éclairs napoleons  école  école lenôtre  ém  ém huge  \n",
       "0                  0      0              0   0        0  \n",
       "1                  1      1              1   1        1  \n",
       "\n",
       "[2 rows x 150034 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fc_df_stacked = fc_df.head(2).stack().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>69</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>385</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>420</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>233</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>309</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1\n",
       "great   69  1501\n",
       "place  385  1485\n",
       "food   420  1241\n",
       "good   233  1235\n",
       "just   309   951"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_df_stacked.sort_values(1, ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>says figured</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sank waders</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sank</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitizing tools</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sanitizing</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0  1\n",
       "says figured      1  0\n",
       "sank waders       1  0\n",
       "sank              1  0\n",
       "sanitizing tools  1  0\n",
       "sanitizing        1  0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_df_stacked.sort_values(1, ascending=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 (Challenge)\n",
    "\n",
    "Browse through the review text of some of the **false positives** and **false negatives**. Based on your knowledge of how Naive Bayes works, do you have any ideas about why the model is incorrectly classifying these reviews?\n",
    "\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains the definitions of \"false positives\" and \"false negatives\".\n",
    "- **Hint:** Think about what a false positive means in this context, and what a false negative means in this context. What has scikit-learn defined as the \"positive class\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nathan's Answer: \n",
    "\n",
    "Many of these seem to have many neutral sentences or background with just one or two particular negative or positive sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([2175, 4556, 1048, 1781, 2674, 9984,  995, 2947, 5833,  281,\n",
       "            ...\n",
       "            3482, 9299, 3960, 6106, 4311, 7035, 8000, 3755,  507, 9037],\n",
       "           dtype='int64', length=149)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise: show the message text for the false positives\n",
    "X_test[y_test < y_pred_class].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Never Again,\\nI brought my Mountain Bike in (which I bought 1 week earlier from Walmart) to have them replace my flat inner tubes with puncture resistant tubes.)  I came back 20 minutes later when they said it would be done and as I rode away, the back tire rhythmically rubbed against the back brake.  When I returned and told them about it, I was told the back wheel was not true.  It was true for the whole short week since I purchased it from Walmart.  I plan to take it to their competitor (Landis) and pay the extra $15-$25) to have the wheel put back to the straight condition it was in when I brought it to Slippery Pig in the first place.   I would never give a shop another penny for an extra service I should never have needed on a brand new bike which coasted perfectly when I brought it in.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[2839]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([750], dtype='int64')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exercise: show the message text for the false negatives\n",
    "X_test[y_test > y_pred_class].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've passed by prestige nails in walmart 100s of times but never really thought of having a pedicure there (even though they are always busy!) As I stared at my feet, long overdue for a pedicure, I thought it was about time to try them...since walmart rarely let's me down why should the nail salon inside?\\n\\nTo my surprise I got a wonderful pedicure or $23 not too bad this day in age...my to mention it was just as good as going to the more upscale salon just across the street! \\n\\nI'm glad to be the first to review them they deserve it! Now if only they did facials at walmart and hair I'd be set!\""
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[2504]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 (Challenge)\n",
    "\n",
    "Up to this point, we have framed this as a **binary classification problem** by only considering the 5-star and 1-star reviews. Now, let's repeat the model building process using all reviews, which makes this a **5-class classification problem**.\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "- Define X and y using the original DataFrame. (y should contain 5 different classes.)\n",
    "- Split X and y into training and testing sets.\n",
    "- Create document-term matrices using CountVectorizer.\n",
    "- Calculate the testing accuracy of a Multinomial Naive Bayes model.\n",
    "- Compare the testing accuracy with the null accuracy.\n",
    "- Print the confusion matrix.\n",
    "- Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.stars \n",
    "\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vect = CountVectorizer(stop_words='english')\n",
    "vect = TfidfVectorizer(sublinear_tf=True, max_df=.5, analyzer='word', stop_words='english', ngram_range=(1, 1))\n",
    "# vect = HashingVectorizer(stop_words='english', analyzer='word', norm=u'l2', ngram_range=(1, 5))\n",
    "\n",
    "\n",
    "# learn training data vocabulary, then create document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.3536\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts().head(1) / len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_multi_models(X_train_dtm, X_test_dtm, y_train, y_test, clf=None):\n",
    "    nb = clf()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    \n",
    "    y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "    accuracy_score = metrics.accuracy_score(y_test, y_pred_class)\n",
    "#     roc_auc = metrics.roc_auc_score(y_test, y_pred_prob)\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "    \n",
    "    print \"\"\"Model: %s \\n \n",
    "    Accuracy Score: %s \\n \n",
    "    ROC AUC Score: %s \\n \n",
    "    Confusion Matrix: %s\n",
    "    \n",
    "    \"\"\" % (clf, accuracy_score, roc_auc, confusion)\n",
    "\n",
    "    return nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'> \n",
      " \n",
      "    Accuracy Score: 0.4332 \n",
      " \n",
      "    ROC AUC Score: 0.770704705821 \n",
      " \n",
      "    Confusion Matrix: [[  0   0   0 147  38]\n",
      " [  0   0   0 214  20]\n",
      " [  0   0   1 341  23]\n",
      " [  0   0   0 780 104]\n",
      " [  0   0   0 530 302]]\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "mnb = nb_multi_models(X_train_dtm, X_test_dtm, y_train, y_test, clf=MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.naive_bayes.BernoulliNB'> \n",
      " \n",
      "    Accuracy Score: 0.4176 \n",
      " \n",
      "    ROC AUC Score: 0.770704705821 \n",
      " \n",
      "    Confusion Matrix: [[ 19  10   7  57  92]\n",
      " [ 12  13  22 112  75]\n",
      " [  6  15  25 183 136]\n",
      " [  8  16  23 410 427]\n",
      " [  6  11   9 229 577]]\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "nbern = nb_multi_models(X_train_dtm, X_test_dtm, y_train, y_test, clf=BernoulliNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.linear_model.logistic.LogisticRegression'> \n",
      " \n",
      "    Accuracy Score: 0.5192 \n",
      " \n",
      "    ROC AUC Score: 0.770704705821 \n",
      " \n",
      "    Confusion Matrix: [[ 61  24  17  36  47]\n",
      " [ 23  34  40  97  40]\n",
      " [  7   9  61 225  63]\n",
      " [  1   0  21 586 276]\n",
      " [  5   0   2 269 556]]\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "lb = nb_multi_models(X_train_dtm, X_test_dtm, y_train, y_test, clf=LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df5 = pd.DataFrame(nbern.feature_count_ , columns=vect.get_feature_names())\n",
    "# df5_stacked = df5.head(2).stack().unstack(0)\n",
    "# df5_stacked.sort_values(1, ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "\n",
    "Looking at the three different models tested, it seems apparent that confusion matrixes tell an interesting story depending on the which parameters where passed into the vectorizer. I noticed that the longer the ngram length that I passed in that less likely certain categories were to be receive a classification (either true or false).\n",
    "\n",
    "As a general note, the advise to review false predictions is well noted. \n",
    "\n",
    "I also noticed how much quicker NB was for training and predicting a model then logistical regression. I imagine with a bigger dataset that this lag would grow with the size of the dataset. \n",
    "\n",
    "In general, it seems apparent that more robust feature extraction is needed.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
