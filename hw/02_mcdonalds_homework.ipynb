{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework with McDonald's sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/mcdonalds.csv', 'data/mcdonalds_new.txt']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafiles = glob.glob('data/**')\n",
    "datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcdo_csv = datafiles[0]\n",
    "mcdo_test = datafiles[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imaginary problem statement\n",
    "\n",
    "McDonald's receives **thousands of customer comments** on their website per day, and many of them are negative. Their corporate employees don't have time to read every single comment, but they do want to read a subset of comments that they are most interested in. In particular, the media has recently portrayed their employees as being rude, and so they want to read any comments about **rude service** so that they can update their employee training accordingly.\n",
    "\n",
    "McDonald's has hired you to develop a system that ranks each comment by the **likelihood that it is referring to rude service**. They will use your system to build a \"rudeness dashboard\" for their corporate employees, so that employees can spend a few minutes each day examining the **most relevant recent comments**.\n",
    "\n",
    "## Description of the data\n",
    "\n",
    "Before hiring you, McDonald's used the [CrowdFlower platform](http://www.crowdflower.com/data-for-everyone) to pay humans to **hand-annotate** about 1500 comments with the **type of complaint**. The complaint types are listed below, with the encoding used in the data listed in parentheses:\n",
    "\n",
    "- Bad Food (BadFood)\n",
    "- Bad Neighborhood (ScaryMcDs)\n",
    "- Cost (Cost)\n",
    "- Dirty Location (Filthy)\n",
    "- Missing Item (MissingFood)\n",
    "- Problem with Order (OrderProblem)\n",
    "- Rude Service (RudeService)\n",
    "- Slow Service (SlowService)\n",
    "- None of the above (na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Read **`mcdonalds.csv`** into a Pandas DataFrame and examine it. (It can be found in the **`data`** directory of the course repository.)\n",
    "\n",
    "- The **policies_violated** column lists the type of complaint. If there is more than one type, the types are separated by newline characters.\n",
    "- The **policies_violated:confidence** column lists CrowdFlower's confidence in the judgments of its human annotators for that row (higher is better).\n",
    "- The **city** column is the McDonald's location.\n",
    "- The **review** column is the actual text comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'_unit_id', u'_golden', u'_unit_state', u'_trusted_judgments',\n",
       "       u'_last_judgment_at', u'policies_violated',\n",
       "       u'policies_violated_confidence', u'city', u'policies_violated_gold',\n",
       "       u'review', u'unnamed__10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(mcdo_csv)\n",
    "df = utils.clean_columns(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1525 entries, 0 to 1524\n",
      "Data columns (total 11 columns):\n",
      "_unit_id                        1525 non-null int64\n",
      "_golden                         1525 non-null bool\n",
      "_unit_state                     1525 non-null object\n",
      "_trusted_judgments              1525 non-null int64\n",
      "_last_judgment_at               1525 non-null object\n",
      "policies_violated               1471 non-null object\n",
      "policies_violated_confidence    1471 non-null object\n",
      "city                            1438 non-null object\n",
      "policies_violated_gold          0 non-null float64\n",
      "review                          1525 non-null object\n",
      "unnamed__10                     0 non-null float64\n",
      "dtypes: bool(1), float64(2), int64(2), object(6)\n",
      "memory usage: 132.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del df['unnamed__10']\n",
    "    del df['policies_violated_gold']\n",
    "except KeyError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['policies_violated'] = df.policies_violated.str.replace('\\n', ',')\n",
    "df['policies_violated_confidence'] = df['policies_violated_confidence'].str.replace('\\n', ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Remove any rows from the DataFrame in which the **policies_violated** column has a **null value**. Check the shape of the DataFrame before and after to confirm that you only removed about 50 rows.\n",
    "\n",
    "- **Note:** Null values are also known as \"missing values\", and are encoded in Pandas with the special value \"NaN\". This is distinct from the \"na\" encoding used by CrowdFlower to denote \"None of the above\". Rows that contain \"na\" should **not** be removed.\n",
    "- **Hint:** This [code snippet](http://chrisalbon.com/python/pandas_missing_data.html) shows different ways for handling missing data in Pandas, and includes one strategy that will work for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1471 entries, 0 to 1524\n",
      "Data columns (total 9 columns):\n",
      "_unit_id                        1471 non-null int64\n",
      "_golden                         1471 non-null bool\n",
      "_unit_state                     1471 non-null object\n",
      "_trusted_judgments              1471 non-null int64\n",
      "_last_judgment_at               1471 non-null object\n",
      "policies_violated               1471 non-null object\n",
      "policies_violated_confidence    1471 non-null object\n",
      "city                            1385 non-null object\n",
      "review                          1471 non-null object\n",
      "dtypes: bool(1), int64(2), object(6)\n",
      "memory usage: 104.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(thresh=8)\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Add a new column to the DataFrame called **\"rude\"** that is 1 if the **policies_violated** column contains \"RudeService\", and 0 if the **policies_violated** column does not contain \"RudeService\". The \"rude\" column is going to be your response variable, so check how many zeros and ones it contains.\n",
    "\n",
    "- **Hint:** This [code snippet](http://chrisalbon.com/python/pandas_string_munging.html) shows how to use a Pandas string method to search for the presence of a sub-string. You will also have to figure out how to convert the boolean results (True/False) to integers (1/0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = utils.make_dummies(df, columns=['city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### This might be overkill, but useful. \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = vect.fit(df.policies_violated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm = vect.transform(df.policies_violated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "policies_violated_df = pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, policies_violated_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>policies_violated</th>\n",
       "      <th>policies_violated_confidence</th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "      <th>...</th>\n",
       "      <th>city_portland</th>\n",
       "      <th>badfood</th>\n",
       "      <th>cost</th>\n",
       "      <th>filthy</th>\n",
       "      <th>missingfood</th>\n",
       "      <th>na</th>\n",
       "      <th>orderproblem</th>\n",
       "      <th>rudeservice</th>\n",
       "      <th>scarymcds</th>\n",
       "      <th>slowservice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>679455653</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/21/15 0:36</td>\n",
       "      <td>RudeService,OrderProblem,Filthy</td>\n",
       "      <td>1.0,0.6667,0.6667</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I'm not a huge mcds lover, but I've been to be...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>679455654</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/21/15 0:27</td>\n",
       "      <td>RudeService</td>\n",
       "      <td>1</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Terrible customer service. ŒæI came in at 9:30...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>679455655</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>2/21/15 0:26</td>\n",
       "      <td>SlowService,OrderProblem</td>\n",
       "      <td>1.0,1.0</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>First they \"lost\" my order, actually they gave...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   _unit_id _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0      0  679455653   False   finalized                   3      2/21/15 0:36   \n",
       "1      1  679455654   False   finalized                   3      2/21/15 0:27   \n",
       "2      2  679455655   False   finalized                   3      2/21/15 0:26   \n",
       "\n",
       "                 policies_violated policies_violated_confidence     city  \\\n",
       "0  RudeService,OrderProblem,Filthy            1.0,0.6667,0.6667  Atlanta   \n",
       "1                      RudeService                            1  Atlanta   \n",
       "2         SlowService,OrderProblem                      1.0,1.0  Atlanta   \n",
       "\n",
       "                                              review     ...       \\\n",
       "0  I'm not a huge mcds lover, but I've been to be...     ...        \n",
       "1  Terrible customer service. ŒæI came in at 9:30...     ...        \n",
       "2  First they \"lost\" my order, actually they gave...     ...        \n",
       "\n",
       "   city_portland  badfood  cost  filthy  missingfood  na  orderproblem  \\\n",
       "0              0        0     0       1            0   0             1   \n",
       "1              0        0     0       0            0   0             0   \n",
       "2              0        0     0       0            0   0             1   \n",
       "\n",
       "   rudeservice  scarymcds  slowservice  \n",
       "0            1          0            0  \n",
       "1            1          0            0  \n",
       "2            0          0            1  \n",
       "\n",
       "[3 rows x 28 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "\n",
    "1. Define X (the **review** column) and y (the **rude** column).\n",
    "2. Split X and y into training and testing sets (using the parameter **`random_state=1`**).\n",
    "3. Use CountVectorizer (with the **default parameters**) to create document-term matrices from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.review\n",
    "y = df.rudeservice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()    \n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "\n",
    "Fit a Multinomial Naive Bayes model to the training set, calculate the **predicted probabilites** (not the class predictions) for the testing set, and then calculate the **AUC**. Repeat this task using a logistic regression model to see which of the two models achieves a better AUC.\n",
    "\n",
    "- **Note:** Because McDonald's only cares about ranking the comments by the likelihood that they refer to rude service, **classification accuracy** is not the relevant evaluation metric. **Area Under the Curve (AUC)** is a more useful evaluation metric for this scenario, since it measures the ability of the classifier to assign higher predicted probabilities to positive instances than to negative instances.\n",
    "- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains how to calculate predicted probabilities and AUC, and my [blog post and video](http://www.dataschool.io/roc-curves-and-auc-explained/) explain AUC in-depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.naive_bayes.BernoulliNB'> \n",
      " \n",
      "    Accuracy Score: 0.673913043478 \n",
      " \n",
      "    ROC AUC Score: 0.656541090447 \n",
      " \n",
      "    Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.86      0.77       233\n",
      "          1       0.59      0.36      0.44       135\n",
      "\n",
      "avg / total       0.66      0.67      0.65       368\n",
      "\n",
      "    \n",
      "    \n",
      "Model: <class 'sklearn.linear_model.logistic.LogisticRegression'> \n",
      " \n",
      "    Accuracy Score: 0.766304347826 \n",
      " \n",
      "    ROC AUC Score: 0.823398505802 \n",
      " \n",
      "    Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.88      0.83       233\n",
      "          1       0.73      0.57      0.64       135\n",
      "\n",
      "avg / total       0.76      0.77      0.76       368\n",
      "\n",
      "    \n",
      "    \n",
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'> \n",
      " \n",
      "    Accuracy Score: 0.798913043478 \n",
      " \n",
      "    ROC AUC Score: 0.841964711493 \n",
      " \n",
      "    Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.89      0.85       233\n",
      "          1       0.77      0.64      0.70       135\n",
      "\n",
      "avg / total       0.80      0.80      0.79       368\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "reload(funcs)\n",
    "for model in  funcs.many_nb_models(X_train_dtm, X_test_dtm, y_train, y_test):\n",
    "    print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "Using either Naive Bayes or logistic regression (whichever one had a better AUC in the previous step), try **tuning CountVectorizer** using some of the techniques we learned in class. Check the testing set **AUC** after each change, and find the set of parameters that increases AUC the most.\n",
    "\n",
    "- **Hint:** It is highly recommended that you adapt the **`tokenize_test()`** function from class for this purpose, since it will allow you to iterate quickly through different sets of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (1e-05, 1e-06),\n",
      " 'clf__penalty': ('l2', 'elasticnet'),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  66 out of  72 | elapsed:   10.8s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 12.275s\n",
      "\n",
      "Best score: 0.787\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__penalty: 'elasticnet'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "reload(tune_countvectorizer)\n",
    "import tune_countvectorizer as tc\n",
    "\n",
    "\n",
    "tc.find_best_cvect_params(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (1e-05,),\n",
      " 'clf__n_iter': (80,),\n",
      " 'clf__penalty': ('l2',),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__analyzer': ('word', 'char_wb'),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__max_features': (None, 5000, 10000, 50000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (2, 2), (2, 3), (2, 4)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 3 folds for each of 480 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:   53.9s\n",
      "[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 800 jobs       | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1250 jobs       | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 out of 1440 | elapsed:  9.4min remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 567.201s\n",
      "\n",
      "Best score: 0.787\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__n_iter: 80\n",
      "\tclf__penalty: 'l2'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: 50000\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n"
     ]
    }
   ],
   "source": [
    "reload(tune_countvectorizer)\n",
    "import tune_countvectorizer as tc\n",
    "\n",
    "tc.find_best_cvect_params(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 (Challenge)\n",
    "\n",
    "The **city** column might be predictive of the response, but we are not currently using it as a feature. Let's see whether we can increase the AUC by adding it to the model:\n",
    "\n",
    "1. Create a new DataFrame column, **review_city**, that includes both the **review** text and the **city** text. One easy way to combine string columns in Pandas is by using the [`Series.str.cat()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.cat.html) method. Make sure to use the **space character** as a separator, as well as replacing **null city values** with a reasonable string value (such as 'na').\n",
    "2. Redefine X as the **review_city** column, and re-split X and y into training and testing sets.\n",
    "3. When you run **`tokenize_test()`**, CountVectorizer will simply treat the city as an extra word in the review, and thus it will automatically be included in the model! Check to see whether it increased or decreased the AUC of your **best model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['review_with_city'] = df['review'].str.cat(df['city'].values.astype(str), sep=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.review_with_city\n",
    "y = df.rudeservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'analyzer':'word', \n",
    "          'max_df':0.75, \n",
    "          'max_features':50000, \n",
    "          'ngram_range':(1, 3), \n",
    "          'lowercase': True,\n",
    "\n",
    "          'stop_words':'english'}\n",
    "\n",
    "vect = CountVectorizer(params)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.naive_bayes.BernoulliNB'> \n",
      " \n",
      "    Accuracy Score: 0.671195652174 \n",
      " \n",
      "    ROC AUC Score: 0.65773326975 \n",
      " \n",
      "    Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.85      0.77       233\n",
      "          1       0.59      0.36      0.44       135\n",
      "\n",
      "avg / total       0.66      0.67      0.65       368\n",
      "\n",
      "    \n",
      "    \n",
      "Model: <class 'sklearn.linear_model.logistic.LogisticRegression'> \n",
      " \n",
      "    Accuracy Score: 0.766304347826 \n",
      " \n",
      "    ROC AUC Score: 0.820696232713 \n",
      " \n",
      "    Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.88      0.83       233\n",
      "          1       0.73      0.57      0.64       135\n",
      "\n",
      "avg / total       0.76      0.77      0.76       368\n",
      "\n",
      "    \n",
      "    \n",
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'> \n",
      " \n",
      "    Accuracy Score: 0.785326086957 \n",
      " \n",
      "    ROC AUC Score: 0.842568749007 \n",
      " \n",
      "    Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.89      0.84       233\n",
      "          1       0.76      0.60      0.67       135\n",
      "\n",
      "avg / total       0.78      0.79      0.78       368\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "reload(funcs)\n",
    "for model in  funcs.many_nb_models(X_train_dtm, X_test_dtm, y_train, y_test):\n",
    "    print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 (Challenge)\n",
    "\n",
    "The **policies_violated:confidence** column may be useful, since it essentially represents a measurement of the training data quality. Let's see whether we can improve the AUC by only training the model using the highest-quality rows:\n",
    "\n",
    "1. Using the [`Series.str.split()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.split.html) method, convert the **policies_violated:confidence** column into lists of one or more \"confidence scores\". Save the results as a new DataFrame column called **confidence_list**.\n",
    "2. Define a function that calculates the mean of a list of numbers, and pass that function to the [`Series.apply()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.apply.html) method for the **confidence_list** column. That will calculate the mean confidence score for each row. Save those scores in a new DataFrame column called **confidence_mean**.\n",
    "3. Create a new DataFrame that only includes the rows with a **confidence_mean** of 1. Compare the shapes of the original and new DataFrames.\n",
    "4. Redefine X and y using the new DataFrame, and re-split X and y into training and testing sets.\n",
    "5. Check to see whether this process increased or decreased the AUC of your **best model**.\n",
    "6. Try **re-tuning** CountVectorizer to maximize the AUC, to see if this strategy was worthwhile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['confidence_list'] =df.policies_violated_confidence.str.split(',').apply(lambda x: np.mean([float(n) for n in x ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fullconf_df = df[df.confidence_list==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = fullconf_df.review_with_city\n",
    "y = fullconf_df.rudeservice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (1e-05,),\n",
      " 'clf__n_iter': (80,),\n",
      " 'clf__penalty': ('l2',),\n",
      " 'tfidf__norm': ('l1', 'l2'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__analyzer': ('word', 'char_wb'),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__max_features': (None, 5000, 10000, 50000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2), (2, 2), (2, 3), (2, 4)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 3 folds for each of 480 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 jobs       | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 jobs       | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 jobs       | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 450 jobs       | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 800 jobs       | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1250 jobs       | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 out of 1440 | elapsed:  4.5min remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 273.563s\n",
      "\n",
      "Best score: 0.868\n",
      "Best parameters set:\n",
      "\tclf__alpha: 1e-05\n",
      "\tclf__n_iter: 80\n",
      "\tclf__penalty: 'l2'\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 2)\n",
      "\tvect__stop_words: 'english'\n"
     ]
    }
   ],
   "source": [
    "reload(tune_countvectorizer)\n",
    "import tune_countvectorizer as tc\n",
    "\n",
    "tc.find_best_cvect_params(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'analyzer':'word', \n",
    "          'max_df':0.5, \n",
    "          'max_features':None, \n",
    "          'ngram_range':(1, 2), \n",
    "          'lowercase': True,\n",
    "          'norm': 'l2',\n",
    "          'use_idf': False,\n",
    "          'stop_words':'english',\n",
    "         }\n",
    "\n",
    "vect = TfidfVectorizer(params)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.naive_bayes.BernoulliNB'> \n",
      " \n",
      "    Accuracy Score: 0.671195652174 \n",
      " \n",
      "    ROC AUC Score: 0.65773326975 \n",
      " \n",
      "    Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.85      0.77       233\n",
      "          1       0.59      0.36      0.44       135\n",
      "\n",
      "avg / total       0.66      0.67      0.65       368\n",
      "\n",
      "    \n",
      "    \n",
      "Model: <class 'sklearn.linear_model.logistic.LogisticRegression'> \n",
      " \n",
      "    Accuracy Score: 0.736413043478 \n",
      " \n",
      "    ROC AUC Score: 0.846383722779 \n",
      " \n",
      "    Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.96      0.82       233\n",
      "          1       0.83      0.36      0.50       135\n",
      "\n",
      "avg / total       0.76      0.74      0.70       368\n",
      "\n",
      "    \n",
      "    \n",
      "Model: <class 'sklearn.naive_bayes.MultinomialNB'> \n",
      " \n",
      "    Accuracy Score: 0.638586956522 \n",
      " \n",
      "    ROC AUC Score: 0.81589572405 \n",
      " \n",
      "    Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78       233\n",
      "          1       1.00      0.01      0.03       135\n",
      "\n",
      "avg / total       0.77      0.64      0.50       368\n",
      "\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "reload(funcs)\n",
    "for model in  funcs.many_nb_models(X_train_dtm, X_test_dtm, y_train, y_test):\n",
    "    print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 (Challenge)\n",
    "\n",
    "New comments have been submitted to the McDonald's website, and you need to **score them with the likelihood** that they are referring to rude service.\n",
    "\n",
    "1. Before making predictions on out-of-sample data, it is important to re-train your model on all relevant data using the tuning parameters and preprocessing steps that produced the best AUC above.\n",
    "    - In other words, X should be defined using either **all rows** or **only those rows with a confidence_mean of 1**, whichever produced a better AUC above.\n",
    "    - X should refer to either the **review column** or the **review_city column**, whichever produced a better AUC above.\n",
    "    - CountVectorizer should be instantiated with the **tuning parameters** that produced the best AUC above.\n",
    "    - **`train_test_split()`** should not be used during this process.\n",
    "2. Build a document-term matrix (from X) called **X_dtm**, and examine its shape.\n",
    "3. Read the new comments stored in **`mcdonalds_new.csv`** into DataFrame called **new_comments**, and examine it.\n",
    "4. If your model uses a **review_city** column, create that column in the new_comments DataFrame. (Otherwise, skip this step.)\n",
    "5. Build a document_term matrix (from the **new_comments** DataFrame) called **new_dtm**, and examine its shape.\n",
    "6. Train your best model (Naive Bayes or logistic regression) using **X_dtm** and **y**.\n",
    "7. Predict the \"rude probability\" for each comment in **new_dtm**, and store the probabilities in an object called **new_pred_prob**.\n",
    "8. Print the **full text** for each new comment alongside its **\"rude probability\"**. Examine the results, and comment on how well you think the model performed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = fullconf_df.review_with_city\n",
    "y = fullconf_df.rudeservice\n",
    "\n",
    "X.shape == y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'analyzer':'word', \n",
    "          'max_df':0.5, \n",
    "          'max_features':None, \n",
    "          'ngram_range':(1, 2), \n",
    "          'lowercase': True,\n",
    "          'norm': 'l2',\n",
    "          'use_idf': False,\n",
    "          'stop_words':'english',\n",
    "         }\n",
    "\n",
    "vect = TfidfVectorizer(params)\n",
    "X_train_dtm = vect.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Went through the drive through and ordered a #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Phenomenal experience. Efficient and friendly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Ghetto lady helped me at the drive thru. Very ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city                                             review\n",
       "0    Las Vegas  Went through the drive through and ordered a #...\n",
       "1      Chicago  Phenomenal experience. Efficient and friendly ...\n",
       "2  Los Angeles  Ghetto lady helped me at the drive thru. Very ..."
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_comments = pd.read_csv(mcdo_test)\n",
    "new_comments.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Went through the drive through and ordered a #...\n",
       "1    Phenomenal experience. Efficient and friendly ...\n",
       "2    Ghetto lady helped me at the drive thru. Very ...\n",
       "3    Close to my workplace. It was well manged befo...\n",
       "4    I've made at least 3 visits to this particular...\n",
       "5    Why did I revisited this McDonald's  again.  I...\n",
       "6    This specific McDonald's is the bar I hold all...\n",
       "7    My friend and I stopped in to get a late night...\n",
       "8    Friendly people but completely unable to deliv...\n",
       "9    Having visited many McDonald's over the years,...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_comments['review_with_city'] = new_comments['review'].str.cat(new_comments['city'].values.astype(str), sep=' ')\n",
    "new_comments.review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_reviews = new_comments['review_with_city']\n",
    "\n",
    "new_comments_dtm = vect.transform(new_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "nb = LogisticRegression()\n",
    "nb.fit(X_train_dtm, y)\n",
    "y_pred_class = nb.predict(new_comments_dtm)\n",
    "\n",
    "y_pred_prob = nb.predict_proba(new_comments_dtm)[:, 1]\n",
    "\n",
    "new_comments['rude_proba'] =  y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "      <th>review_with_city</th>\n",
       "      <th>rude_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>My friend and I stopped in to get a late night...</td>\n",
       "      <td>My friend and I stopped in to get a late night...</td>\n",
       "      <td>0.573713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Ghetto lady helped me at the drive thru. Very ...</td>\n",
       "      <td>Ghetto lady helped me at the drive thru. Very ...</td>\n",
       "      <td>0.466396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Went through the drive through and ordered a #...</td>\n",
       "      <td>Went through the drive through and ordered a #...</td>\n",
       "      <td>0.344322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Portland</td>\n",
       "      <td>I've made at least 3 visits to this particular...</td>\n",
       "      <td>I've made at least 3 visits to this particular...</td>\n",
       "      <td>0.266857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Friendly people but completely unable to deliv...</td>\n",
       "      <td>Friendly people but completely unable to deliv...</td>\n",
       "      <td>0.250615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Phenomenal experience. Efficient and friendly ...</td>\n",
       "      <td>Phenomenal experience. Efficient and friendly ...</td>\n",
       "      <td>0.238424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Having visited many McDonald's over the years,...</td>\n",
       "      <td>Having visited many McDonald's over the years,...</td>\n",
       "      <td>0.197025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>This specific McDonald's is the bar I hold all...</td>\n",
       "      <td>This specific McDonald's is the bar I hold all...</td>\n",
       "      <td>0.190381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Houston</td>\n",
       "      <td>Why did I revisited this McDonald's  again.  I...</td>\n",
       "      <td>Why did I revisited this McDonald's  again.  I...</td>\n",
       "      <td>0.171670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York</td>\n",
       "      <td>Close to my workplace. It was well manged befo...</td>\n",
       "      <td>Close to my workplace. It was well manged befo...</td>\n",
       "      <td>0.140397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          city                                             review  \\\n",
       "7       Dallas  My friend and I stopped in to get a late night...   \n",
       "2  Los Angeles  Ghetto lady helped me at the drive thru. Very ...   \n",
       "0    Las Vegas  Went through the drive through and ordered a #...   \n",
       "4     Portland  I've made at least 3 visits to this particular...   \n",
       "8    Cleveland  Friendly people but completely unable to deliv...   \n",
       "1      Chicago  Phenomenal experience. Efficient and friendly ...   \n",
       "9          NaN  Having visited many McDonald's over the years,...   \n",
       "6      Atlanta  This specific McDonald's is the bar I hold all...   \n",
       "5      Houston  Why did I revisited this McDonald's  again.  I...   \n",
       "3     New York  Close to my workplace. It was well manged befo...   \n",
       "\n",
       "                                    review_with_city  rude_proba  \n",
       "7  My friend and I stopped in to get a late night...    0.573713  \n",
       "2  Ghetto lady helped me at the drive thru. Very ...    0.466396  \n",
       "0  Went through the drive through and ordered a #...    0.344322  \n",
       "4  I've made at least 3 visits to this particular...    0.266857  \n",
       "8  Friendly people but completely unable to deliv...    0.250615  \n",
       "1  Phenomenal experience. Efficient and friendly ...    0.238424  \n",
       "9  Having visited many McDonald's over the years,...    0.197025  \n",
       "6  This specific McDonald's is the bar I hold all...    0.190381  \n",
       "5  Why did I revisited this McDonald's  again.  I...    0.171670  \n",
       "3  Close to my workplace. It was well manged befo...    0.140397  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_comments.sort_values('rude_proba', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rude Proba: 0.344321810886 \n",
      "\n",
      "Went through the drive through and ordered a #10 (cripsy sweet chili chicken wrap) without fries- the lady couldn't understand that I did not want fries and charged me for them anyways. I got the wrong order- a chicken sandwich and a large fries- my boyfriend took it back inside to get the correct order. The gentleman that ordered the chicken sandwich was standing there as well and she took the bag from my bf- glanced at the insides and handed it to the man without even offering to replace. I mean with all the scares about viruses going around... ugh DISGUSTING SERVICE. Then when she gave him the correct order my wrap not only had the sweet chili sauce on it, but the nasty (just not my first choice) ranch dressing on it!!!! I mean seriously... how lazy can you get!!!! I worked at McDonalds in Texas when I was 17 for about 8 months and I guess I was spoiled with good management. This was absolutely ridiculous. I was beyond disappointed.\n",
      "\n",
      "____________________\n",
      "\n",
      "Rude Proba: 0.238424250601 \n",
      "\n",
      "Phenomenal experience. Efficient and friendly staff. Clean restrooms, good, fast service and bilingual staff. One of the best restaurants in the chain.\n",
      "\n",
      "____________________\n",
      "\n",
      "Rude Proba: 0.466396386256 \n",
      "\n",
      "Ghetto lady helped me at the drive thru. Very rude and disrespectful to the co workers. Never coming back. Yuck!\n",
      "\n",
      "____________________\n",
      "\n",
      "Rude Proba: 0.140396920352 \n",
      "\n",
      "Close to my workplace. It was well manged before. Now it's OK. The parking can be tight sometimes. Like all McDonald's, prices are getting expensive.\n",
      "\n",
      "____________________\n",
      "\n",
      "Rude Proba: 0.266856979955 \n",
      "\n",
      "I've made at least 3 visits to this particular location just because it's right next to my office building.. and all my experience have been consistently bad.  There are a few helpers taking your orders throughout the drive-thru route and they are the worst. They rush you in placing an order and gets impatient once the order gets a tad bit complicated.  Don't even bother changing your mind oh NO! They will glare at you and snap at you if you want to change something.  I understand its FAST food, but I want my order placed right.  Not going back if I can help it.\n",
      "\n",
      "____________________\n",
      "\n",
      "Rude Proba: 0.171669608598 \n",
      "\n",
      "Why did I revisited this McDonald's  again.  I needed to use the restroom  facilities  and the women's bathroom didn't have soap, the floor was wet,  the bathroom stink, and the toilets were nasty. This McDonald's is very nasty.\n",
      "\n",
      "____________________\n",
      "\n",
      "Rude Proba: 0.190380734 \n",
      "\n",
      "This specific McDonald's is the bar I hold all other fast food joints to now. Been working in this area for 3 years now and gone to this location many times for drive-through pickup. Service is always fast, food comes out right, and the staff is extremely warm and polite.\n",
      "\n",
      "____________________\n",
      "\n",
      "Rude Proba: 0.573713103624 \n",
      "\n",
      "My friend and I stopped in to get a late night snack and we were refused service. The store claimed to be 24 hours and the manager was standing right there doing paper work but would not help us. The cashier was only concerned with doing things for the drive thru and said that the manager said he wasn't allowed to help us. We thought it was a joke at first but when realized it wasn't we said goodbye and they just let us leave. I work in a restaurant and this is by far the worst service I have ever seen. I know it was late and maybe they didn't want to be there but it was completely ridiculous. I think the manager should be fired.\n",
      "\n",
      "____________________\n",
      "\n",
      "Rude Proba: 0.250614956913 \n",
      "\n",
      "Friendly people but completely unable to deliver what was ordered at the drive through.  Out of my last 6 orders they got it right 3 times.  Incidentally, the billing was always correct - they just could not read the order and deliver.  Very frustrating!\n",
      "\n",
      "____________________\n",
      "\n",
      "Rude Proba: 0.197025394119 \n",
      "\n",
      "Having visited many McDonald's over the years, I have to say that this one is the most efficient one ever! Even though it is still fast food, the service at the drive-thru is the best. They rarely make a mistake and I never see anyone parked in the drive-thru slots where they bring food out because they don't have it ready. So, if you like McDonald's fast food, it doesn't get any better than this.\n",
      "\n",
      "____________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index in new_comments.index:\n",
    "    row = new_comments.loc[index]\n",
    "    print 'Rude Proba: %s \\n' % (row.rude_proba) \n",
    "    print row.review\n",
    "    print '\\n' + '_'*20 + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ghetto lady helped me at the drive thru. Very rude and disrespectful to the co workers. Never coming back. Yuck!'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_comments.loc[2].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Went through the drive through and ordered a #10 (cripsy sweet chili chicken wrap) without fries- the lady couldn't understand that I did not want fries and charged me for them anyways. I got the wrong order- a chicken sandwich and a large fries- my boyfriend took it back inside to get the correct order. The gentleman that ordered the chicken sandwich was standing there as well and she took the bag from my bf- glanced at the insides and handed it to the man without even offering to replace. I mean with all the scares about viruses going around... ugh DISGUSTING SERVICE. Then when she gave him the correct order my wrap not only had the sweet chili sauce on it, but the nasty (just not my first choice) ranch dressing on it!!!! I mean seriously... how lazy can you get!!!! I worked at McDonalds in Texas when I was 17 for about 8 months and I guess I was spoiled with good management. This was absolutely ridiculous. I was beyond disappointed.\""
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_comments.loc[0].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've made at least 3 visits to this particular location just because it's right next to my office building.. and all my experience have been consistently bad.  There are a few helpers taking your orders throughout the drive-thru route and they are the worst. They rush you in placing an order and gets impatient once the order gets a tad bit complicated.  Don't even bother changing your mind oh NO! They will glare at you and snap at you if you want to change something.  I understand its FAST food, but I want my order placed right.  Not going back if I can help it.\""
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_comments.loc[4].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Friendly people but completely unable to deliver what was ordered at the drive through.  Out of my last 6 orders they got it right 3 times.  Incidentally, the billing was always correct - they just could not read the order and deliver.  Very frustrating!'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_comments.loc[8].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
